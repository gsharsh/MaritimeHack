---
phase: 02-milp-optimizer
plan: 02
type: execute
---

<objective>
Wire MILP solver into run.py and fix column name mismatches in optimization helpers.

Purpose: Make the MILP solver callable from the CLI entry point, producing a complete fleet selection result with metrics and validation.
Output: `python run.py` loads data, runs MILP, prints selected fleet with metrics.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-milp-optimizer/02-01-SUMMARY.md

@src/optimization.py
@src/constants.py
@src/data_adapter.py
@run.py

**Tech stack available:** pandas, PuLP>=2.7.0, pytest
**Established patterns:** functional/procedural, constants from src/constants.py

**Constraining decisions:**
- Phase 1: run.py kept minimal as staging script
- Phase 2 Plan 01: select_fleet_milp() exists and is tested

**Column name mismatch (MUST FIX):**
The existing `total_cost_and_metrics()` and `validate_fleet()` in optimization.py use default column names that DON'T match per_vessel.csv:
- `cost_col="total_cost_usd"` → should be `"final_cost"`
- `fuel_col="fuel_tonnes"` → should be `"FC_total"`
- `co2e_col="co2e_tonnes"` → should be `"CO2eq"`
These defaults must be updated to match the actual CSV column names.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix column name defaults and wire MILP into run.py</name>
  <files>src/optimization.py, run.py</files>
  <action>
  1. In `src/optimization.py`, update `total_cost_and_metrics()` default parameter values:
     - `cost_col="total_cost_usd"` → `cost_col="final_cost"`
     - `fuel_col="fuel_tonnes"` → `fuel_col="FC_total"`
     - `co2e_col="co2e_tonnes"` → `co2e_col="CO2eq"`

  2. In `run.py`, after loading data and printing summary:
     - Import `select_fleet_milp` from `src.optimization`
     - Import `validate_fleet`, `total_cost_and_metrics`, `format_outputs` from `src.optimization`
     - Call `selected_ids = select_fleet_milp(df)` with defaults from constants
     - Handle empty result (infeasible): print error and exit(1)
     - Call `ok, errors = validate_fleet(df, selected_ids, MONTHLY_DEMAND, SAFETY_THRESHOLD, True)`
     - Print validation result and any errors
     - Call `metrics = total_cost_and_metrics(df, selected_ids)`
     - Call `formatted = format_outputs(metrics)`
     - Print formatted results
     - Print selected vessel IDs list
     - Remove the "Ready for Phase 2" placeholder message

  Keep run.py clean — no try/except around the solver (let errors propagate).
  Do NOT add file output yet (that's Phase 6).
  </action>
  <verify>
  ```bash
  python run.py
  ```
  Should print: data summary, MILP result (selected vessels, fleet size, total cost, DWT, safety, CO2eq), validation PASS.
  With fixtures (5 vessels), expect all 5 selected since total DWT (855,421) < MONTHLY_DEMAND (4,576,667) — actually this means the problem is infeasible with fixtures! So test with relaxed demand:
  ```bash
  python -c "from src.data_adapter import load_per_vessel; from src.optimization import select_fleet_milp; df = load_per_vessel(); print(select_fleet_milp(df, cargo_demand=500000, min_avg_safety=1.0, require_all_fuel_types=False))"
  ```
  Should return a subset of vessel IDs.

  For run.py with fixtures, either: (a) run.py handles infeasible gracefully, or (b) use --cargo-demand flag. Prefer (a): if infeasible, print warning that fixtures don't have enough DWT, still show the attempt.
  </verify>
  <done>
  - `python run.py` runs without errors (with fixtures, shows infeasible message gracefully)
  - `total_cost_and_metrics()` defaults match per_vessel.csv columns
  - MILP solver is called from run.py
  - All existing tests still pass: `python -m pytest -v`
  </done>
</task>

<task type="auto">
  <name>Task 2: Add --cargo-demand and --safety-threshold CLI args for testing</name>
  <files>run.py</files>
  <action>
  Add two optional CLI arguments to run.py:
  - `--cargo-demand` (float, default=MONTHLY_DEMAND) — allows testing with lower demand on fixtures
  - `--safety-threshold` (float, default=SAFETY_THRESHOLD) — allows testing different safety levels

  Pass these to `select_fleet_milp(df, cargo_demand=args.cargo_demand, min_avg_safety=args.safety_threshold)`.

  This enables testing with fixtures:
  ```bash
  python run.py --cargo-demand 500000 --safety-threshold 1.0
  ```
  Which should produce a valid fleet selection from the 5 fixture vessels.
  </action>
  <verify>
  ```bash
  # Test with relaxed constraints on fixtures
  python run.py --cargo-demand 500000 --safety-threshold 1.0

  # Test with default (infeasible on fixtures - should print graceful message)
  python run.py

  # All tests still pass
  python -m pytest -v
  ```
  </verify>
  <done>
  - `python run.py --cargo-demand 500000 --safety-threshold 1.0` selects vessels and prints metrics
  - `python run.py` with fixtures prints infeasible message (not a crash)
  - All existing tests pass
  - Phase 2 complete
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -m pytest -v` — all tests pass (including test_milp.py from Plan 01)
- [ ] `python run.py --cargo-demand 500000 --safety-threshold 1.0` — selects fleet, prints metrics
- [ ] `python run.py` with fixtures — handles infeasible gracefully
- [ ] No import errors or missing dependencies
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- MILP solver is callable from CLI
- Column name defaults match per_vessel.csv
- run.py handles both feasible and infeasible cases
- Phase 2 complete: MILP Fleet Optimizer functional
</success_criteria>

<output>
After completion, create `.planning/phases/02-milp-optimizer/02-02-SUMMARY.md`:

# Phase 2 Plan 02: Wire MILP into run.py Summary

**[one-liner]**

## Accomplishments
- [outcomes]

## Files Created/Modified
- [files]

## Decisions Made
- [decisions]

## Issues Encountered
- [issues]

## Next Step
Phase 2 complete, ready for Phase 3 (Validation)
</output>
