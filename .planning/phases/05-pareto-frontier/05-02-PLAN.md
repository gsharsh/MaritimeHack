---
phase: 05-pareto-frontier
plan: 02
type: execute
---

<objective>
Implement carbon price sweep and wire all Phase 5 analyses into CLI.

Purpose: Show how fleet composition changes at different carbon prices ($80/$120/$160/$200), and make Pareto + carbon sweep accessible from command line.
Output: run_carbon_price_sweep() function, --pareto and --carbon-sweep CLI flags in run.py.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-pareto-frontier/05-01-SUMMARY.md
@src/optimization.py
@src/sensitivity.py
@src/constants.py
@run.py

**Tech stack available:** pulp, pandas
**Established patterns:** sweep-loop-over-milp-thresholds, infeasible-detection, CLI flag pattern from --sweep
**Constraining decisions:**
- Phase 04: Sweep pattern: loop thresholds, call MILP, collect metrics dict per threshold
- Phase 04: Infeasible thresholds shown as INFEASIBLE in table (not omitted)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement run_carbon_price_sweep()</name>
  <files>src/sensitivity.py</files>
  <action>Add run_carbon_price_sweep() to sensitivity.py. Algorithm:
1. Accept df (DataFrame), carbon_prices list (default [80, 120, 160, 200]), and cargo_demand/safety_threshold params.
2. For each carbon_price in the list:
   a. Recalculate the final_cost column: final_cost = total_monthly + risk_premium. The risk_premium includes carbon_cost. But carbon_cost itself = CO2eq * carbon_price / 12 (monthly). The simplest approach: df already has columns for the cost components. The final_cost currently uses CARBON_PRICE=80. To sweep, we need to recompute: new_carbon_cost = df["CO2eq"] * new_carbon_price (if CO2eq is annual) or adjust accordingly. Look at how final_cost is composed: from per_vessel.csv it has carbon_cost as a column. So: new_final_cost = df["final_cost"] - df["carbon_cost"] + df["CO2eq"] * new_carbon_price. Wait — need to check. The per_vessel.csv has carbon_cost column which is CO2eq * 80. So: adjusted_final_cost = df["final_cost"] - df["carbon_cost"] + df["CO2eq"] * new_carbon_price. Create a copy of df, replace final_cost, then call select_fleet_milp on the copy.
   b. Call select_fleet_milp(df_copy, cargo_demand, safety_threshold) — no CO2 cap needed.
   c. Collect metrics using total_cost_and_metrics on df_copy (so costs reflect the new carbon price).
3. Return list of dicts: carbon_price, feasible, fleet_size, total_cost_usd, total_co2e_tonnes, avg_safety_score, total_dwt, selected_ids, fuel_type_counts.

Also add format_carbon_sweep_table(results) returning a DataFrame: Carbon Price ($/t), Feasible, Fleet Size, Total Cost ($), Total CO2eq (t), Avg Safety. Same formatting pattern as other tables.

NOTE: If the test fixtures don't have a carbon_cost column, handle gracefully — if "carbon_cost" not in df.columns, compute it as df["CO2eq"] * 80 (base carbon price) before adjusting. Import CARBON_PRICE from constants for the fallback.</action>
  <verify>Run `python -m pytest tests/ -v` — all existing tests still pass. `python -c "from src.sensitivity import run_carbon_price_sweep, format_carbon_sweep_table; print('OK')"` succeeds.</verify>
  <done>run_carbon_price_sweep() and format_carbon_sweep_table() exist. Function recalculates final_cost at each carbon price and re-solves MILP. Returns list of dicts with fleet metrics per carbon price.</done>
</task>

<task type="auto">
  <name>Task 2: Wire Pareto and carbon sweep into run.py CLI</name>
  <files>run.py</files>
  <action>Add two new CLI flags following the existing --sweep pattern:
1. `--pareto` (store_true, default False): "Run cost-emissions Pareto frontier (epsilon-constraint, 15 points)"
2. `--carbon-sweep` (store_true, default False): "Run carbon price sweep at $80/$120/$160/$200"

Import run_pareto_sweep, format_pareto_table, run_carbon_price_sweep, format_carbon_sweep_table from src.sensitivity.

After the existing sweep section in main(), add:

For --pareto:
- Print header "Cost-Emissions Pareto Frontier"
- Call run_pareto_sweep(df, cargo_demand=args.cargo_demand)
- Print format_pareto_table(results).to_string(index=False)
- Print summary: "Pareto points: N feasible out of 15"

For --carbon-sweep:
- Print header "Carbon Price Sweep"
- Call run_carbon_price_sweep(df, cargo_demand=args.cargo_demand, safety_threshold=args.safety_threshold)
- Print format_carbon_sweep_table(results).to_string(index=False)
- Print fuel composition per carbon price (same pattern as --sweep fuel composition output)

Keep output formatting consistent with existing --sweep section (same banner style, separator lines).</action>
  <verify>Run `python -m pytest tests/ -v` — all tests pass. Run `python run.py --help` and confirm --pareto and --carbon-sweep appear in help text.</verify>
  <done>--pareto flag triggers Pareto frontier analysis. --carbon-sweep flag triggers carbon price sweep. Both produce formatted table output. Help text shows all flags. All existing tests pass.</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -m pytest tests/ -v` passes all tests
- [ ] `python run.py --help` shows --pareto and --carbon-sweep flags
- [ ] All Phase 5 functions importable without errors
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- No regressions in existing tests
- Carbon price sweep recalculates final_cost correctly
- CLI flags work and produce formatted output
- Phase 5 complete
</success_criteria>

<output>
After completion, create `.planning/phases/05-pareto-frontier/05-02-SUMMARY.md`
</output>
