---
phase: 04-safety-threshold-sweep
plan: 01
type: execute
---

<objective>
Implement safety threshold sweep: re-run MILP at thresholds 3.0, 3.5, 4.0, 4.5, collect fleet metrics at each level, and output a comparison table.

Purpose: Step 10 of the SOP — compare how fleet cost, size, composition, and emissions change as the safety requirement tightens.
Output: Working `run_safety_sweep()` function in sensitivity.py, integrated into run.py with `--sweep` flag, printing a comparison table.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Key files (from prior phases):
@src/optimization.py
@src/sensitivity.py
@src/constants.py
@run.py

**Tech stack available:** pulp, pandas, argparse
**Established patterns:** binary MILP fleet selection via select_fleet_milp(), linearized avg safety constraint, empty list on infeasible, total_cost_and_metrics() for aggregation
**Constraining decisions:**
- Phase 02-01: Linearized safety constraint sum(safety_i - threshold) >= 0
- Phase 02-01: Return empty list on infeasible (not raise)
- Phase 02-02: Column defaults: final_cost, FC_total, CO2eq
- Phase 02-02: Infeasible exits with sys.exit(1) for CLI
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement run_safety_sweep() in sensitivity.py</name>
  <files>src/sensitivity.py</files>
  <action>
Replace the stub functions in src/sensitivity.py with:

1. `run_safety_sweep(df, thresholds, cargo_demand)` that:
   - Takes a DataFrame, list of safety thresholds (default [3.0, 3.5, 4.0, 4.5]), and cargo_demand (default MONTHLY_DEMAND)
   - For each threshold, calls `select_fleet_milp(df, cargo_demand, min_avg_safety=t)`
   - If result is empty list, record that threshold as infeasible (all metrics = None/NaN)
   - Otherwise calls `total_cost_and_metrics(df, selected_ids)` and also computes fuel_type_counts (value_counts of main_engine_fuel_type for selected vessels)
   - Returns a list of dicts, one per threshold, with keys: threshold, feasible, fleet_size, total_cost_usd, avg_safety_score, total_co2e_tonnes, total_dwt, total_fuel_tonnes, fuel_type_counts, selected_ids

2. `format_sweep_table(results)` that:
   - Takes the list of dicts from run_safety_sweep
   - Returns a pandas DataFrame with columns: Threshold, Feasible, Fleet Size, Total Cost ($), Avg Safety, Total CO2eq (t), Total DWT, Total Fuel (t)
   - Format cost with comma separators and 2 decimal places
   - Mark infeasible rows clearly

Import select_fleet_milp and total_cost_and_metrics from src.optimization, MONTHLY_DEMAND from src.constants.

Do NOT add logging, type checking, or error handling beyond detecting infeasible (empty list). Keep it simple — this is a loop calling an already-tested MILP function.
  </action>
  <verify>python -c "from src.sensitivity import run_safety_sweep, format_sweep_table; print('imports ok')"</verify>
  <done>run_safety_sweep() and format_sweep_table() importable, no syntax errors</done>
</task>

<task type="auto">
  <name>Task 2: Wire sweep into run.py and verify end-to-end</name>
  <files>run.py</files>
  <action>
Add `--sweep` boolean flag to argparse in run.py (default False).

After the existing MILP results output block, add a sweep section guarded by `if args.sweep`:
1. Import run_safety_sweep, format_sweep_table from src.sensitivity
2. Call run_safety_sweep(df, thresholds=[3.0, 3.5, 4.0, 4.5], cargo_demand=args.cargo_demand)
3. Print section header "Safety Threshold Sweep"
4. Print the formatted table using format_sweep_table(results).to_string(index=False)
5. For each feasible result, print a one-line fuel type composition summary (e.g., "Threshold 3.0: 8 types — DISTILLATE FUEL: 5, LNG: 3, ...")

Do NOT change any existing run.py behavior — only append the sweep block after the existing output. Move the sensitivity import to the top of the file alongside other imports.
  </action>
  <verify>python run.py --sweep 2>&1 | head -80</verify>
  <done>--sweep flag works, prints comparison table for 4 thresholds, infeasible thresholds detected and labeled, existing non-sweep output unchanged</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `python -c "from src.sensitivity import run_safety_sweep, format_sweep_table"` succeeds
- [ ] `python run.py` (without --sweep) still works identically to before
- [ ] `python run.py --sweep` prints base results AND sweep comparison table
- [ ] Sweep table shows 4 rows (thresholds 3.0, 3.5, 4.0, 4.5)
- [ ] Higher thresholds show higher cost or infeasible (monotonic cost increase expected)
- [ ] `pytest` — all existing tests still pass (no regressions)
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- No regressions in existing tests
- Sweep correctly detects infeasible thresholds
- Cost increases monotonically with stricter safety threshold (or becomes infeasible)
- Phase 4 complete
</success_criteria>

<output>
After completion, create `.planning/phases/04-safety-threshold-sweep/04-01-SUMMARY.md`
</output>
